### YamlMime:PythonEnum
uid: azure.cognitiveservices.speech.PropertyId
name: PropertyId
fullName: azure.cognitiveservices.speech.PropertyId
summary: "Defines speech property ids.\n\n*Values:*\n\n   SpeechServiceConnection_Key\n\
  \n\n      The Cognitive Services Speech Service subscription key. If you are using\n\
  \n      an intent recognizer, you need to specify the LUIS endpoint key for your\n\
  \n      particular LUIS app. Under normal circumstances, you shouldn't have to\n\
  \n      use this property directly. Instead, construct a\n\n      <xref:azure.cognitiveservices.speech.SpeechConfig>\
  \ instance from a subscription key.\n\n   SpeechServiceConnection_Endpoint\n\n\n\
  \      The Cognitive Services Speech Service endpoint (url). Under normal\n\n  \
  \    circumstances, you shouldn't have to use this property directly. Instead,\n\
  \n      construct a <xref:azure.cognitiveservices.speech.SpeechConfig> instance\
  \ from a subscription key.\n\n\n      > [!NOTE]\n      > This endpoint is not the\
  \ same as the endpoint used to obtain an access token.\n      >\n\n   SpeechServiceConnection_Region\n\
  \n\n      The Cognitive Services Speech Service region. Under normal circumstances,\n\
  \n      you shouldn't have to use this property directly. Instead, construct a\n\
  \n      <xref:azure.cognitiveservices.speech.SpeechConfig> instance from a subscription\
  \ key, an endpoint, a host,\n\n      or an authorization token.\n\n   SpeechServiceAuthorization_Token\n\
  \n\n      The Cognitive Services Speech Service authorization token (aka access\n\
  \n      token). Under normal circumstances, you shouldn't have to use this\n\n \
  \     property directly. Instead, construct a <xref:azure.cognitiveservices.speech.SpeechConfig>\n\
  \n      instance from an authorization token, or set\n\n      <xref:Recognizer.authorization_token>.\n\
  \n   SpeechServiceAuthorization_Type\n\n\n      The Cognitive Services Speech Service\
  \ authorization type. Currently\n\n      unused.\n\n   SpeechServiceConnection_EndpointId\n\
  \n\n      The Cognitive Services Custom Speech or Custom Voice Service endpoint\
  \ id.\n\n      Under normal circumstances, you shouldn't have to use this property\
  \ directly.\n\n      Instead set <xref:SpeechConfig.endpoint_id>.\n\n\n      > [!NOTE]\n\
  \      > The endpoint id is available in the Custom Speech Portal, listed under\n\
  \      >\n      > \n      >\n      > Endpoint Details.\n      >\n\n   SpeechServiceConnection_Host\n\
  \n\n      The Cognitive Services Speech Service host (url). Under normal\n\n   \
  \   circumstances, you shouldn't have to use this property directly. Instead,\n\n\
  \      construct a <xref:azure.cognitiveservices.speech.SpeechConfig> instance.\n\
  \n   SpeechServiceConnection_ProxyHostName\n\n\n      The host name of the proxy\
  \ server used to connect to the Cognitive\n\n      Services Speech Service. Under\
  \ normal circumstances, you shouldn't have\n\n      to use this property directly.\
  \ Instead, use\n\n      <xref:SpeechConfig.set_proxy>.\n\n   SpeechServiceConnection_ProxyPort\n\
  \n\n      The port of the proxy server used to connect to the Cognitive Services\n\
  \n      Speech Service. Under normal circumstances, you shouldn't have to use\n\n\
  \      this property directly. Instead, use <xref:SpeechConfig.set_proxy>.\n\n \
  \  SpeechServiceConnection_ProxyUserName\n\n\n      The user name of the proxy server\
  \ used to connect to the Cognitive\n\n      Services Speech Service. Under normal\
  \ circumstances, you shouldn't have\n\n      to use this property directly. Instead,\
  \ use\n\n      <xref:SpeechConfig.set_proxy>.\n\n   SpeechServiceConnection_ProxyPassword\n\
  \n\n      The password of the proxy server used to connect to the Cognitive\n\n\
  \      Services Speech Service. Under normal circumstances, you shouldn't have\n\
  \n      to use this property directly. Instead, use\n\n      <xref:SpeechConfig.set_proxy>.\n\
  \n   SpeechServiceConnection_Url\n\n\n      The URL string built from speech configuration.\
  \ This property is intended\n\n      to be read-only. The SDK is using it internally.\n\
  \n\n      > [!NOTE]\n      > This property id was added in version 1.5.0.\n    \
  \  >\n\n   SpeechServiceConnection_TranslationToLanguages\n\n\n      The list of\
  \ comma separated languages used as target translation\n\n      languages. Under\
  \ normal circumstances, you shouldn't have to use this\n\n      property directly.\
  \ Instead use\n\n      <xref:SpeechTranslationConfig.add_target_language> and\n\n\
  \      <xref:SpeechTranslationConfig.target_languages>.\n\n   SpeechServiceConnection_TranslationVoice\n\
  \n\n      The name of the Cognitive Service Text to Speech Service voice. Under\n\
  \n      normal circumstances, you shouldn't have to use this property directly.\n\
  \n      Instead set <xref:SpeechTranslationConfig.voice_name>.\n\n\n      > [!NOTE]\n\
  \      > Valid voice names can be found [here](https://aka.ms/csspeech/voicenames).\n\
  \      >\n\n   SpeechServiceConnection_TranslationFeatures\n\n\n      Translation\
  \ features. For internal use.\n\n   SpeechServiceConnection_IntentRegion\n\n\n \
  \     The Language Understanding Service region. Under normal circumstances,\n\n\
  \      you shouldn't have to use this property directly. Instead use\n\n      <xref:azure.cognitiveservices.speech.LanguageUnderstandingModel>.\n\
  \n   SpeechServiceConnection_RecoMode\n\n\n      The Cognitive Services Speech Service\
  \ recognition mode. Can be\n\n      \"INTERACTIVE\", \"CONVERSATION\", \"DICTATION\"\
  . This property is intended to\n\n      be read-only. The SDK is using it internally.\n\
  \n   SpeechServiceConnection_RecoLanguage\n\n\n      The spoken language to be recognized\
  \ (in BCP-47 format). Under normal\n\n      circumstances, you shouldn't have to\
  \ use this property directly. Instead,\n\n      use <xref:SpeechConfig.speech_recognition_language>.\n\
  \n   Speech_SessionId\n\n\n      The session id. This id is a universally unique\
  \ identifier (aka UUID)\n\n      representing a specific binding of an audio input\
  \ stream and the\n\n      underlying speech recognition instance to which it is\
  \ bound. Under normal\n\n      circumstances, you shouldn't have to use this property\
  \ directly. Instead\n\n      use <xref:SessionEventArgs.session_id>.\n\n   SpeechServiceConnection_SynthLanguage\n\
  \n\n      The spoken language to be synthesized (e.g. en-US)\n\n\n      > [!NOTE]\n\
  \      > This property id was added in version 1.7.0.\n      >\n\n   SpeechServiceConnection_SynthVoice\n\
  \n\n      The name of the TTS voice to be used for speech synthesis\n\n\n      >\
  \ [!NOTE]\n      > This property id was added in version 1.7.0.\n      >\n\n   SpeechServiceConnection_SynthOutputFormat\n\
  \n\n      The string to specify TTS output audio format\n\n\n      > [!NOTE]\n \
  \     > This property id was added in version 1.7.0.\n      >\n\n   SpeechServiceConnection_InitialSilenceTimeoutMs\n\
  \n\n      The initial silence timeout value (in milliseconds) used by the service.\n\
  \n\n      > [!NOTE]\n      > This property id was added in version 1.5.0.\n    \
  \  >\n\n   SpeechServiceConnection_EndSilenceTimeoutMs\n\n\n      The end silence\
  \ timeout value (in milliseconds) used by the service.\n\n\n      > [!NOTE]\n  \
  \    > This property id was added in version 1.5.0.\n      >\n\n   SpeechServiceConnection_EnableAudioLogging\n\
  \n\n      A boolean value specifying whether audio logging is enabled in the service\
  \ or not.\n\n\n      > [!NOTE]\n      > This property id was added in version 1.5.0.\n\
  \      >\n\n   SpeechServiceResponse_RequestDetailedResultTrueFalse\n\n\n      The\
  \ requested Cognitive Services Speech Service response output format\n\n      (simple\
  \ or detailed). Under normal circumstances, you shouldn't have to\n\n      use this\
  \ property directly. Instead use\n\n      <xref:SpeechConfig.output_format>.\n\n\
  \   SpeechServiceResponse_RequestProfanityFilterTrueFalse\n\n\n      The requested\
  \ Cognitive Services Speech Service response output profanity\n\n      level. Currently\
  \ unused.\n\n   SpeechServiceResponse_ProfanityOption\n\n\n      The requested Cognitive\
  \ Services Speech Service response output profanity\n\n      setting. Allowed values\
  \ are \"masked\", \"removed\", and \"raw\".\n\n\n      > [!NOTE]\n      > This property\
  \ id was added in version 1.5.0.\n      >\n\n   SpeechServiceResponse_PostProcessingOption\n\
  \n\n      A string value specifying which post processing option should be used\
  \ by\n\n      service.  Allowed values are \"TrueText\".\n\n\n      > [!NOTE]\n\
  \      > This property id was added in version 1.5.0.\n      >\n\n   SpeechServiceResponse_RequestWordLevelTimestamps\n\
  \n\n      A boolean value specifying whether to include word-level timestamps in\
  \ the\n\n      response result.\n\n\n      > [!NOTE]\n      > This property id was\
  \ added in version 1.5.0.\n      >\n\n   SpeechServiceResponse_StablePartialResultThreshold\n\
  \n\n      The number of times a word has to be in partial results to be returned.\n\
  \n\n      > [!NOTE]\n      > This property id was added in version 1.5.0.\n    \
  \  >\n\n   SpeechServiceResponse_OutputFormatOption\n\n\n      A string value specifying\
  \ the output format option in the response result.\n\n      Internal use only.\n\
  \n\n      > [!NOTE]\n      > This property id was added in version 1.5.0.\n    \
  \  >\n\n   SpeechServiceResponse_OutputFormatOption\n\n\n      A boolean value to\
  \ request for stabilizing translation partial results by omitting words in the end.\n\
  \n\n      > [!NOTE]\n      > This property id was added in version 1.5.0.\n    \
  \  >\n\n   SpeechServiceResponse_JsonResult\n\n\n      The Cognitive Services Speech\
  \ Service response output (in JSON format).\n\n      This property is available\
  \ as <xref:RecognitionResult.json>.\n\n   SpeechServiceResponse_JsonErrorDetails\n\
  \n\n      The Cognitive Services Speech Service error details (in JSON format).\n\
  \n      Under normal circumstances, you shouldn't have to use this property\n\n\
  \      directly. This property is available as\n\n      <xref:RecognitionResult.error_json>.\n\
  \n   SpeechServiceResponse_RecognitionLatencyMs\n\n\n      The recognition latency\
  \ in milliseconds. Read-only, available on final\n\n      speech/translation/intent\
  \ results. This measures the latency between\n\n      when an audio input is received\
  \ by the SDK, and the moment the final\n\n      result is received from the service.\
  \ The SDK computes the time\n\n      difference between the last audio fragment\
  \ from the audio input that is\n\n      contributing to the final result, and the\
  \ time the final result is\n\n      received from the speech service.\n\n\n    \
  \  > [!NOTE]\n      > This property id was added in version 1.3.0.\n      >\n\n\
  \   CancellationDetails_Reason\n\n\n      The cancellation reason. Currently unused.\n\
  \n   CancellationDetails_ReasonText\n\n\n      The cancellation text. Currently\
  \ unused.\n\n   CancellationDetails_ReasonDetailedText\n\n\n      The cancellation\
  \ detailed text. Currently unused.\n\n   LanguageUnderstandingServiceResponse_JsonResult\n\
  \n\n      The Language Understanding Service response output (in JSON format).\n\
  \n      This property is available as\n\n      <xref:IntentRecognitionResult.intent_json>.\n\
  \n   AudioConfig_DeviceNameForCapture\n\n\n      The device name for audio capture.\
  \ Under normal circumstances, you shouldn't have to\n\n      use this property directly.\n\
  \n      Instead, use the *device_name* parameter to construct a *AudioConfig* instance.\n\
  \n\n      > [!NOTE]\n      > This property id was added in version 1.3.0.\n    \
  \  >\n\n   AudioConfig_NumberOfChannelsForCapture\n\n\n      The number of channels\
  \ for audio capture. Internal use only.\n\n\n      > [!NOTE]\n      > This property\
  \ id was added in version 1.3.0.\n      >\n\n   AudioConfig_SampleRateForCapture\n\
  \n\n      The sample rate (in Hz) for audio capture. Internal use only.\n\n\n  \
  \    > [!NOTE]\n      > This property id was added in version 1.3.0.\n      >\n\n\
  \   AudioConfig_BitsPerSampleForCapture\n\n\n      The number of bits of each sample\
  \ for audio capture. Internal use only.\n\n\n      > [!NOTE]\n      > This property\
  \ id was added in version 1.3.0.\n      >\n\n   AudioConfig_AudioSource\n\n\n  \
  \    The audio source. Allowed values are \"Microphones\", \"File\", and \"Stream\"\
  .\n\n\n      > [!NOTE]\n      > This property id was added in version 1.3.0.\n \
  \     >\n\n   Speech_LogFilename\n\n\n      The file name to write logs.\n\n\n \
  \     > [!NOTE]\n      > This property id was added in version 1.4.0.\n      >\n\
  \n   PronunciationAssessment_ReferenceText\n\n\n      The reference text of the\
  \ audio for pronunciation evaluation.\n\n      For this and the following pronunciation\
  \ assessment parameters, see\n\n      [https://docs.microsoft.com/azure/cognitive-services/speech-service/rest-speech-to-text#pronunciation-assessment-parameters](https://docs.microsoft.com/azure/cognitive-services/speech-service/rest-speech-to-text#pronunciation-assessment-parameters)\
  \ for details.\n\n      Under normal circumstances, you shouldn't have to use this\
  \ property directly.\n\n\n      > [!NOTE]\n      > This property id was added in\
  \ version 1.4.0.\n      >\n\n   PronunciationAssessment_GradingSystem\n\n\n    \
  \  The point system for pronunciation score calibration (FivePoint or HundredMark).\n\
  \n      Under normal circumstances, you shouldn't have to use this property directly.\n\
  \n\n      > [!NOTE]\n      > This property id was added in version 1.4.0.\n    \
  \  >\n\n   PronunciationAssessment_Granularity\n\n\n      The pronunciation evaluation\
  \ granularity (Phoneme, Word, or FullText).\n\n      Under normal circumstances,\
  \ you shouldn't have to use this property directly.\n\n\n      > [!NOTE]\n     \
  \ > This property id was added in version 1.4.0.\n      >\n\n   PronunciationAssessment_EnableMiscue\n\
  \n\n      Defines if enable miscue calculation.\n\n      With this enabled, the\
  \ pronounced words will be compared to the reference text,\n\n      and will be\
  \ marked with omission/insertion based on the comparison.\n\n      When disabled,\
  \ the recognized text will always be reference text. The default setting is False.\n\
  \n      Under normal circumstances, you shouldn't have to use this property directly.\n\
  \n\n      > [!NOTE]\n      > This property id was added in version 1.4.0.\n    \
  \  >\n\n   PronunciationAssessment_Json\n\n\n      The json string of pronunciation\
  \ assessment parameters\n\n      Under normal circumstances, you shouldn't have\
  \ to use this property directly.\n\n\n      > [!NOTE]\n      > This property id\
  \ was added in version 1.4.0.\n      >\n\n   PronunciationAssessment_Params\n\n\n\
  \      Pronunciation assessment parameters.\n\n      This property is intended to\
  \ be read-only. The SDK is using it internally.\n\n\n      > [!NOTE]\n      > This\
  \ property id was added in version 1.4.0.\n      >"
module: azure.cognitiveservices.speech
inheritances:
- enum.Enum
fields:
- name: AudioConfig_AudioSource
  uid: azure.cognitiveservices.speech.PropertyId.AudioConfig_AudioSource
- name: AudioConfig_BitsPerSampleForCapture
  uid: azure.cognitiveservices.speech.PropertyId.AudioConfig_BitsPerSampleForCapture
- name: AudioConfig_DeviceNameForCapture
  uid: azure.cognitiveservices.speech.PropertyId.AudioConfig_DeviceNameForCapture
- name: AudioConfig_DeviceNameForRender
  uid: azure.cognitiveservices.speech.PropertyId.AudioConfig_DeviceNameForRender
- name: AudioConfig_NumberOfChannelsForCapture
  uid: azure.cognitiveservices.speech.PropertyId.AudioConfig_NumberOfChannelsForCapture
- name: AudioConfig_PlaybackBufferLengthInMs
  uid: azure.cognitiveservices.speech.PropertyId.AudioConfig_PlaybackBufferLengthInMs
- name: AudioConfig_SampleRateForCapture
  uid: azure.cognitiveservices.speech.PropertyId.AudioConfig_SampleRateForCapture
- name: CancellationDetails_Reason
  uid: azure.cognitiveservices.speech.PropertyId.CancellationDetails_Reason
- name: CancellationDetails_ReasonDetailedText
  uid: azure.cognitiveservices.speech.PropertyId.CancellationDetails_ReasonDetailedText
- name: CancellationDetails_ReasonText
  uid: azure.cognitiveservices.speech.PropertyId.CancellationDetails_ReasonText
- name: Conversation_ApplicationId
  uid: azure.cognitiveservices.speech.PropertyId.Conversation_ApplicationId
- name: Conversation_Conversation_Id
  uid: azure.cognitiveservices.speech.PropertyId.Conversation_Conversation_Id
- name: Conversation_Custom_Voice_Deployment_Ids
  uid: azure.cognitiveservices.speech.PropertyId.Conversation_Custom_Voice_Deployment_Ids
- name: Conversation_DialogType
  uid: azure.cognitiveservices.speech.PropertyId.Conversation_DialogType
- name: Conversation_From_Id
  uid: azure.cognitiveservices.speech.PropertyId.Conversation_From_Id
- name: Conversation_Initial_Silence_Timeout
  uid: azure.cognitiveservices.speech.PropertyId.Conversation_Initial_Silence_Timeout
- name: Conversation_ParticipantId
  uid: azure.cognitiveservices.speech.PropertyId.Conversation_ParticipantId
- name: Conversation_Request_Bot_Status_Messages
  uid: azure.cognitiveservices.speech.PropertyId.Conversation_Request_Bot_Status_Messages
- name: Conversation_Speech_Activity_Template
  uid: azure.cognitiveservices.speech.PropertyId.Conversation_Speech_Activity_Template
- name: DataBuffer_TimeStamp
  uid: azure.cognitiveservices.speech.PropertyId.DataBuffer_TimeStamp
- name: DataBuffer_UserId
  uid: azure.cognitiveservices.speech.PropertyId.DataBuffer_UserId
- name: LanguageUnderstandingServiceResponse_JsonResult
  uid: azure.cognitiveservices.speech.PropertyId.LanguageUnderstandingServiceResponse_JsonResult
- name: PronunciationAssessment_EnableMiscue
  uid: azure.cognitiveservices.speech.PropertyId.PronunciationAssessment_EnableMiscue
- name: PronunciationAssessment_GradingSystem
  uid: azure.cognitiveservices.speech.PropertyId.PronunciationAssessment_GradingSystem
- name: PronunciationAssessment_Granularity
  uid: azure.cognitiveservices.speech.PropertyId.PronunciationAssessment_Granularity
- name: PronunciationAssessment_Json
  uid: azure.cognitiveservices.speech.PropertyId.PronunciationAssessment_Json
- name: PronunciationAssessment_Params
  uid: azure.cognitiveservices.speech.PropertyId.PronunciationAssessment_Params
- name: PronunciationAssessment_ReferenceText
  uid: azure.cognitiveservices.speech.PropertyId.PronunciationAssessment_ReferenceText
- name: SpeechServiceAuthorization_Token
  uid: azure.cognitiveservices.speech.PropertyId.SpeechServiceAuthorization_Token
- name: SpeechServiceAuthorization_Type
  uid: azure.cognitiveservices.speech.PropertyId.SpeechServiceAuthorization_Type
- name: SpeechServiceConnection_AutoDetectSourceLanguageResult
  uid: azure.cognitiveservices.speech.PropertyId.SpeechServiceConnection_AutoDetectSourceLanguageResult
- name: SpeechServiceConnection_AutoDetectSourceLanguages
  uid: azure.cognitiveservices.speech.PropertyId.SpeechServiceConnection_AutoDetectSourceLanguages
- name: SpeechServiceConnection_EnableAudioLogging
  uid: azure.cognitiveservices.speech.PropertyId.SpeechServiceConnection_EnableAudioLogging
- name: SpeechServiceConnection_EndSilenceTimeoutMs
  uid: azure.cognitiveservices.speech.PropertyId.SpeechServiceConnection_EndSilenceTimeoutMs
- name: SpeechServiceConnection_Endpoint
  uid: azure.cognitiveservices.speech.PropertyId.SpeechServiceConnection_Endpoint
- name: SpeechServiceConnection_EndpointId
  uid: azure.cognitiveservices.speech.PropertyId.SpeechServiceConnection_EndpointId
- name: SpeechServiceConnection_Host
  uid: azure.cognitiveservices.speech.PropertyId.SpeechServiceConnection_Host
- name: SpeechServiceConnection_InitialSilenceTimeoutMs
  uid: azure.cognitiveservices.speech.PropertyId.SpeechServiceConnection_InitialSilenceTimeoutMs
- name: SpeechServiceConnection_IntentRegion
  uid: azure.cognitiveservices.speech.PropertyId.SpeechServiceConnection_IntentRegion
- name: SpeechServiceConnection_Key
  uid: azure.cognitiveservices.speech.PropertyId.SpeechServiceConnection_Key
- name: SpeechServiceConnection_ProxyHostName
  uid: azure.cognitiveservices.speech.PropertyId.SpeechServiceConnection_ProxyHostName
- name: SpeechServiceConnection_ProxyPassword
  uid: azure.cognitiveservices.speech.PropertyId.SpeechServiceConnection_ProxyPassword
- name: SpeechServiceConnection_ProxyPort
  uid: azure.cognitiveservices.speech.PropertyId.SpeechServiceConnection_ProxyPort
- name: SpeechServiceConnection_ProxyUserName
  uid: azure.cognitiveservices.speech.PropertyId.SpeechServiceConnection_ProxyUserName
- name: SpeechServiceConnection_RecoLanguage
  uid: azure.cognitiveservices.speech.PropertyId.SpeechServiceConnection_RecoLanguage
- name: SpeechServiceConnection_RecoMode
  uid: azure.cognitiveservices.speech.PropertyId.SpeechServiceConnection_RecoMode
- name: SpeechServiceConnection_Region
  uid: azure.cognitiveservices.speech.PropertyId.SpeechServiceConnection_Region
- name: SpeechServiceConnection_SynthLanguage
  uid: azure.cognitiveservices.speech.PropertyId.SpeechServiceConnection_SynthLanguage
- name: SpeechServiceConnection_SynthOutputFormat
  uid: azure.cognitiveservices.speech.PropertyId.SpeechServiceConnection_SynthOutputFormat
- name: SpeechServiceConnection_SynthVoice
  uid: azure.cognitiveservices.speech.PropertyId.SpeechServiceConnection_SynthVoice
- name: SpeechServiceConnection_TranslationFeatures
  uid: azure.cognitiveservices.speech.PropertyId.SpeechServiceConnection_TranslationFeatures
- name: SpeechServiceConnection_TranslationToLanguages
  uid: azure.cognitiveservices.speech.PropertyId.SpeechServiceConnection_TranslationToLanguages
- name: SpeechServiceConnection_TranslationVoice
  uid: azure.cognitiveservices.speech.PropertyId.SpeechServiceConnection_TranslationVoice
- name: SpeechServiceConnection_Url
  uid: azure.cognitiveservices.speech.PropertyId.SpeechServiceConnection_Url
- name: SpeechServiceConnection_UserDefinedQueryParameters
  uid: azure.cognitiveservices.speech.PropertyId.SpeechServiceConnection_UserDefinedQueryParameters
- name: SpeechServiceResponse_JsonErrorDetails
  uid: azure.cognitiveservices.speech.PropertyId.SpeechServiceResponse_JsonErrorDetails
- name: SpeechServiceResponse_JsonResult
  uid: azure.cognitiveservices.speech.PropertyId.SpeechServiceResponse_JsonResult
- name: SpeechServiceResponse_OutputFormatOption
  uid: azure.cognitiveservices.speech.PropertyId.SpeechServiceResponse_OutputFormatOption
- name: SpeechServiceResponse_PostProcessingOption
  uid: azure.cognitiveservices.speech.PropertyId.SpeechServiceResponse_PostProcessingOption
- name: SpeechServiceResponse_ProfanityOption
  uid: azure.cognitiveservices.speech.PropertyId.SpeechServiceResponse_ProfanityOption
- name: SpeechServiceResponse_RecognitionLatencyMs
  uid: azure.cognitiveservices.speech.PropertyId.SpeechServiceResponse_RecognitionLatencyMs
- name: SpeechServiceResponse_RequestDetailedResultTrueFalse
  uid: azure.cognitiveservices.speech.PropertyId.SpeechServiceResponse_RequestDetailedResultTrueFalse
- name: SpeechServiceResponse_RequestProfanityFilterTrueFalse
  uid: azure.cognitiveservices.speech.PropertyId.SpeechServiceResponse_RequestProfanityFilterTrueFalse
- name: SpeechServiceResponse_RequestWordLevelTimestamps
  uid: azure.cognitiveservices.speech.PropertyId.SpeechServiceResponse_RequestWordLevelTimestamps
- name: SpeechServiceResponse_StablePartialResultThreshold
  uid: azure.cognitiveservices.speech.PropertyId.SpeechServiceResponse_StablePartialResultThreshold
- name: SpeechServiceResponse_TranslationRequestStablePartialResult
  uid: azure.cognitiveservices.speech.PropertyId.SpeechServiceResponse_TranslationRequestStablePartialResult
- name: Speech_LogFilename
  uid: azure.cognitiveservices.speech.PropertyId.Speech_LogFilename
- name: Speech_SessionId
  uid: azure.cognitiveservices.speech.PropertyId.Speech_SessionId
